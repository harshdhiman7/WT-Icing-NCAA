{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gJVVdFcZ2Ozq"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cpMFUfPy-Ixz"
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('icing_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EgHSCjf2Ht1M"
   },
   "outputs": [],
   "source": [
    "df.index=df.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qoAB-oQTBZgc"
   },
   "outputs": [],
   "source": [
    "df=df.iloc[:,1:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sa-kUDO4Nz-_"
   },
   "outputs": [],
   "source": [
    "df['Delta_T']=df['Ambient temperature [C]'].diff(1)\n",
    "df['Delta_P']=df['output power [kW]'].diff(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "id": "0XNTtWdEQsYy",
    "outputId": "e2c4dec1-2a6d-405a-8885-64b87806dffa"
   },
   "outputs": [],
   "source": [
    "df=df.fillna(0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "XfUDlG9yyUsq",
    "outputId": "04a6ca4a-9c33-4ff0-eff9-cdf33221e469"
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A1KYEGSVYFmD"
   },
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 779
    },
    "id": "c5Oa2sFpBzPr",
    "outputId": "b4873c2e-5691-43e0-f0b5-8424fdb2da1e"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "fig, axs = plt.subplots(4, 2, figsize=(10, 10))\n",
    "colors=[\"skyblue\",\"teal\",\"olive\",\"gold\",\"red\",\"blue\",\"black\"]\n",
    "#for i in range(1,8,1):\n",
    "plt.subplot(4,2,1)\n",
    "    #sns.histplot(data=df, x=df.iloc[:,i-1], kde=False, color=colors[i-1])\n",
    "    #plt.plot(df.iloc[:,i-1],color=colors[i-1])\n",
    "sns.lineplot(data=df, x=df.index,y=df.iloc[:,i-1],color=colors[i-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 366
    },
    "id": "upuHv1VPRpyU",
    "outputId": "4baa347e-c61e-4727-f59c-110a58a89e18"
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(data=df,x=df['Ambient temperature [C]'],y=df['output power [kW]'],hue=\"Ice detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "id": "GvuOfYDQXWdD",
    "outputId": "5a66c63d-4043-41a8-9c6a-cdcaa7acb4f5"
   },
   "outputs": [],
   "source": [
    "sns.boxplot(x=df['Ice detected'],y=df['output power [kW]'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "id": "u185pAHVb1YL",
    "outputId": "bb388940-ae29-498e-f93e-49dc1eae43cf"
   },
   "outputs": [],
   "source": [
    "sns.histplot(data=df, x=\"output power [kW]\", hue=\"Ice detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d6W8_xWifnYI"
   },
   "outputs": [],
   "source": [
    "label=df['Ice detected']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hTMmh1xEcY5E"
   },
   "source": [
    "## Feature Engineering Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "roXpi4cRcbuj"
   },
   "outputs": [],
   "source": [
    "features=df.iloc[:,[0,1,2,3,5,6]]\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "Xtransformed=scaler.fit_transform(features)\n",
    "df_new=pd.DataFrame(Xtransformed,columns=['Windspeed','Wind_direction','Temp','Power','Delta_T','Delta_P'])\n",
    "df_new.index=df.index\n",
    "df_new['Label']=label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "id": "6cWaCUFefRkT",
    "outputId": "8258afb6-40ca-4dae-acff-29a2cbd63466"
   },
   "outputs": [],
   "source": [
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 361
    },
    "id": "5ztKHfncHbB5",
    "outputId": "c8cb61f6-527f-4825-ab8e-70dadf7cb9a5"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(8, 6), dpi=300)  # Set figure size and high DPI\n",
    "sns.set_theme(style='white')  # Keep your theme\n",
    "sns.heatmap(df_new.iloc[:3500, :].corr(), annot=True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CwSqyI_bBFuN"
   },
   "outputs": [],
   "source": [
    "df_1=df_new.loc[df_new['Label']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LWnjFX3zCjHP"
   },
   "outputs": [],
   "source": [
    "Xtrain_1=df_1.iloc[:,:6]\n",
    "ytrain_1=df_1.iloc[:,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XSoIG0xkehTi"
   },
   "outputs": [],
   "source": [
    "sns.histplot(data=df_new, x=\"Power\", hue=\"Label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lfi-Uphmpn7w"
   },
   "outputs": [],
   "source": [
    "X=df_new.iloc[:,:-1]\n",
    "y=df_new.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZAERFr6zeR74"
   },
   "outputs": [],
   "source": [
    "lst = [1,2,3,4,5,6,7,8]\n",
    "def sliding_window(elements, window_size):\n",
    "    if len(elements)== window_size:\n",
    "        return elements\n",
    "    for i in range(0,len(elements) - window_size,1):\n",
    "        print(elements[i:i+window_size])\n",
    "sliding_window(lst, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bwp7LXqdelcp"
   },
   "source": [
    "## Transformer Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GeDFHVsJwFla"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X=np.array(X)\n",
    "y=np.array(y)\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(X,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Avlmzeowwbsw"
   },
   "outputs": [],
   "source": [
    "xtrain = xtrain.reshape((xtrain.shape[0],xtrain.shape[1],1))\n",
    "xtest = xtest.reshape((xtest.shape[0],xtest.shape[1],1))\n",
    "n_classes = len(np.unique(ytrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jMKv8jgLxTZM"
   },
   "outputs": [],
   "source": [
    "print(xtrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bfAcPgmow_XH"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sGcKQZXuxESg"
   },
   "outputs": [],
   "source": [
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "    # Normalization and Attention\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
    "    x = layers.MultiHeadAttention(\n",
    "        key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
    "    )(x, x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    res = x + inputs\n",
    "\n",
    "    # Feed Forward Part\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(res)\n",
    "    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
    "    return x + res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s_ZeOs6vxTT-"
   },
   "outputs": [],
   "source": [
    "def build_model(input_shape,head_size,num_heads,ff_dim,num_transformer_blocks,mlp_units,dropout=0,mlp_dropout=0,):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    x = inputs\n",
    "    for _ in range(num_transformer_blocks):\n",
    "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
    "\n",
    "    x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n",
    "    for dim in mlp_units:\n",
    "        x = layers.Dense(dim, activation=\"relu\")(x)\n",
    "        x = layers.Dropout(mlp_dropout)(x)\n",
    "    outputs = layers.Dense(n_classes, activation=\"softmax\")(x)\n",
    "    return keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "00Rqhwg-xqRz"
   },
   "outputs": [],
   "source": [
    "input_shape = xtrain.shape[1:]\n",
    "\n",
    "model = build_model(input_shape,head_size=256,num_heads=1,ff_dim=4,num_transformer_blocks=4,mlp_units=[128],mlp_dropout=0.4,dropout=0.25,)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
    "metrics=[\"accuracy\"],)\n",
    "model.summary()\n",
    "callbacks = [keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)]\n",
    "model.fit(xtrain,ytrain,validation_split=0.2,epochs=25,batch_size=256,callbacks=callbacks,verbose=1)\n",
    "ypred=model.predict(xtest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y2IoDEtIzBqn"
   },
   "outputs": [],
   "source": [
    "model.evaluate(xtest, ytest, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a4OtLFhkFXVK"
   },
   "outputs": [],
   "source": [
    "#Convert prob into labels\n",
    "out=[]\n",
    "for i in range((ypred.shape[0])):\n",
    "    if ypred[i,0]>ypred[i,1]:\n",
    "       out.append(0)\n",
    "    else:\n",
    "       out.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZiKzg8XTZdKK"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(ytest,out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a6qQcPI7KbFM"
   },
   "outputs": [],
   "source": [
    "#plot icing probability\n",
    "fig = plt.figure(figsize =(8,4))\n",
    "fig.set_dpi(250)\n",
    "#fig = plt.figure(facecolor =\"white\")\n",
    "\n",
    "kernel_size=20\n",
    "kernel=np.ones(kernel_size)/kernel_size\n",
    "data_convolved = np.convolve(ypred[:,1], kernel, mode='same')\n",
    "\n",
    "plt.plot(data_convolved,color='black',lw=1)\n",
    "plt.xlabel('Timestamp/10 mins')\n",
    "plt.ylabel('Icing probability')\n",
    "plt.savefig(\"icing_probability.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RMb0ozySRTTT"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize =(7,2))\n",
    "fig.set_dpi(150)\n",
    "plt.hist(ypred[:,0])\n",
    "plt.hist(ypred[:,1])\n",
    "plt.xlabel('Probability')\n",
    "plt.ylabel('Counts')\n",
    "plt.legend(['Non-icing','Icing'],loc=9)\n",
    "plt.savefig(\"icing_probability_hist.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AAG23FGnFDsK"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "cm=confusion_matrix(ytest,out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4RCbtvmSpXN8"
   },
   "outputs": [],
   "source": [
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UTsNYxjpc7tU"
   },
   "outputs": [],
   "source": [
    "print(classification_report(ytest,out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1jx0MhBfeano"
   },
   "source": [
    "## SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IoTYhT1RegKp"
   },
   "outputs": [],
   "source": [
    "import imblearn\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RkdTbhykjVfX"
   },
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AxYHd_KajoVF"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4pJeVuHyja5h"
   },
   "outputs": [],
   "source": [
    "def evaluate_model(xtrain, ytrain, xtest, ytest,p):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=p, kernel_size=3, activation='relu', input_shape=(xtrain.shape[1],1)))\n",
    "    model.add(Conv1D(filters=p, kernel_size=3, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.fit(xtrain, ytrain, epochs=25, batch_size=128, verbose=1)\n",
    "    _, accuracy = model.evaluate(xtest, ytest, batch_size=128, verbose=1)\n",
    "    ypred_CNN=model.predict(xtest)\n",
    "    #cm_CNN=confusion_matrix(ytest,ypred_CNN)\n",
    "    return ypred_CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "19aWXjhGv12z"
   },
   "outputs": [],
   "source": [
    "def summarize_results(scores, params):\n",
    "\tprint(scores, params)\n",
    "\t# summarize mean and standard deviation\n",
    "\tfor i in range(len(scores)):\n",
    "\t\tm, s = mean(scores[i]), std(scores[i])\n",
    "\t\tprint('Param=%d: %.3f%% (+/-%.3f)' % (params[i], m, s))\n",
    "\t# boxplot of scores\n",
    "\tpyplot.boxplot(scores, labels=params)\n",
    "\tpyplot.savefig('exp_cnn_kernel.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V4tbbK6Gia5t"
   },
   "outputs": [],
   "source": [
    "#def run_experiment(xtrain, ytrain, xtest, ytest,params, repeats=10):\n",
    "\t# load data\n",
    "\t#trainX, trainy, testX, testy = load_dataset()\n",
    "\t# test each parameter\n",
    "#\t\tall_scores = list()\n",
    "#\t\tfor p in params:\n",
    "#\t\t\t\tprint(\"Model training..... for filter size {}\".format(p))\n",
    "#\t\t\t\tscores = list()\n",
    "#\t\t\t\tfor r in range(repeats):\n",
    "#\t\t\t\t\t  cm_CNN = evaluate_model(xtrain, ytrain, xtest, ytest,p)\n",
    "#\t\t\t\t#score = score * 100\n",
    "#\t\t\t\t#print('>p=%d #%d: %.3f' % (p, r+1, score))\n",
    "#\t  \t\t    print('Confusion matrix for filter size {}'.format(p) 'is',cm_CNN)\n",
    "#\t\t\t\t\tscores.append(score)\n",
    "#\t\tall_scores.append(scores)\n",
    "\t# summarize results\n",
    "\t#summarize_results(all_scores, params)\n",
    "\n",
    "# run the experiment\n",
    "n_params = 8\n",
    "#run_experiment(xtrain, ytrain, xtest, ytest,n_params)\n",
    "#xtrain1=X_train_compressed\n",
    "#print(xtrain1.shape)\n",
    "#ytrain1=y_train\n",
    "#xtest1=X_test_compressed\n",
    "#ytest1=y_test\n",
    "evaluate_model(xtrain,ytrain,xtest,ytest,n_params)\n",
    "#evaluate_model(X_train_compressed, y_train, X_test_compressed,y_test,n_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2SfmWJ1J4i3j"
   },
   "outputs": [],
   "source": [
    "ypred_CNN= model.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xJUvMWMWhMOF"
   },
   "outputs": [],
   "source": [
    "#Convert prob into labels\n",
    "out=[]\n",
    "ypred=ypred_CNN\n",
    "for i in range((ypred.shape[0])):\n",
    "    if ypred[i,0]>ypred[i,1]:\n",
    "       out.append(0)\n",
    "    else:\n",
    "       out.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ya_ywBiKhZmk"
   },
   "outputs": [],
   "source": [
    "#plot icing probability\n",
    "fig = plt.figure(figsize =(8,4))\n",
    "fig.set_dpi(250)\n",
    "#fig = plt.figure(facecolor =\"white\")\n",
    "\n",
    "kernel_size=20\n",
    "kernel=np.ones(kernel_size)/kernel_size\n",
    "data_convolved = np.convolve(ypred[:,1], kernel, mode='same')\n",
    "\n",
    "plt.plot(data_convolved,color='black',lw=1)\n",
    "plt.xlabel('Timestamp/10 mins')\n",
    "plt.ylabel('Icing probability')\n",
    "plt.savefig(\"icing_probability.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jz7lB-rKhhX7"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize =(7,2))\n",
    "fig.set_dpi(150)\n",
    "plt.hist(ypred[:,0])\n",
    "plt.hist(ypred[:,1])\n",
    "plt.xlabel('Probability')\n",
    "plt.ylabel('Counts')\n",
    "plt.legend(['Non-icing','Icing'],loc=9)\n",
    "plt.savefig(\"icing_probability_hist.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gWNFvj9j7ij_"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(ytest,ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PXFQQ5sPSwC6"
   },
   "source": [
    "# CNN-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oDO8hYGeS910"
   },
   "outputs": [],
   "source": [
    "X=np.array(X)\n",
    "y=np.array(y)\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(X,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_tBNYYuSZxg1"
   },
   "outputs": [],
   "source": [
    "def CNN_LSTM(xtrain,ytrain,xtest,ytest,n_steps, n_length, n_features):\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense\n",
    "    from keras.layers import Flatten\n",
    "    from keras.layers import Dropout\n",
    "    from keras.layers import LSTM\n",
    "    from keras.layers import TimeDistributed\n",
    "    from keras.layers.convolutional import Conv1D\n",
    "    from keras.layers.convolutional import MaxPooling1D\n",
    "    xtrain = xtrain.reshape((xtrain.shape[0], n_steps,n_features, n_length))\n",
    "    xtest = xtest.reshape((xtest.shape[0], n_steps, n_features, n_length))\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='relu'),input_shape=(None,1,1)))\n",
    "    model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='relu')))\n",
    "    model.add(TimeDistributed(Dropout(0.5)))\n",
    "    model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "    model.add(LSTM(100))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    print(\"CNN-LSTM Model training begins.....\")\n",
    "    import time\n",
    "    start=time.time()\n",
    "    model.fit(xtrain, ytrain, epochs=25, batch_size=128, verbose=1)\n",
    "    stop=time.time()\n",
    "    ypred_CNN_LSTM=model.predict(xtest)\n",
    "    from sklearn.metrics import classification_report\n",
    "    #clf=classification_report(ytest,ypred_CNN_LSTM)\n",
    "    cm_CNN_LSTM=confusion_matrix(ytest,ypred_CNN_LSTM)\n",
    "    return print(cm_CNN_LSTM),print(\"The training time for CNN-LSTM is{} seconds\".format(stop-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-BNJdLnFa2C9"
   },
   "outputs": [],
   "source": [
    "CNN_LSTM(xtrain,ytrain,xtest,ytest,1,1,xtrain.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mBTrRu_te6mH"
   },
   "source": [
    "# ML techniques- SVM, DT, RF, Logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WL4bJJ7-fAcd"
   },
   "outputs": [],
   "source": [
    "def MLModels(X,y,name):\n",
    "    acc=[] #empty list for accuracy\n",
    "    from statistics import mean\n",
    "    Xtrain,Xtest,ytrain,ytest=train_test_split(X,y,test_size=0.2)\n",
    "    if name=='SVM':\n",
    "       from sklearn.svm import SVC\n",
    "       import math\n",
    "       kernel_list=['linear','poly','rbf','sigmoid']\n",
    "       for i in kernel_list:\n",
    "          model_SVC=SVC(kernel=i)\n",
    "          model_SVC.fit(Xtrain,ytrain)\n",
    "          yhat_SVC=model_SVC.predict(Xtest)\n",
    "          acc.append([i,model_SVC.score(Xtest,ytest)])\n",
    "    elif name=='DT':\n",
    "         from sklearn.tree import DecisionTreeClassifier\n",
    "         for i in range(1,50):\n",
    "             model_tree=DecisionTreeClassifier(criterion=\"gini\",max_depth=i,min_samples_leaf=5)\n",
    "             model_tree.fit(Xtrain,ytrain)\n",
    "             y_tree=model_tree.predict(Xtest)\n",
    "             acc.append(model_tree.score(Xtest,ytest))\n",
    "         acc=mean(acc)\n",
    "    else:\n",
    "         from sklearn.neighbors import KNeighborsClassifier\n",
    "         for k in range(1,10):\n",
    "              model=KNeighborsClassifier(n_neighbors=k)\n",
    "              #start_time=datetime.now()\n",
    "              model.fit(Xtrain,ytrain)\n",
    "              #end_time=datetime.now()\n",
    "              #acc=model.score(X_train,y_train)*100\n",
    "              #ft=end_time-start_time\n",
    "              yhat=model.predict(Xtest)\n",
    "              acc.append(model.score(Xtest,ytest))\n",
    "         acc=mean(acc)\n",
    "    return print(\"The accuracy for {} is {}\".format(name,acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aFnHAKHqozpL"
   },
   "outputs": [],
   "source": [
    "MLModels(X,y,'KNN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m-p0Vfkbu-tK"
   },
   "source": [
    "# Generative Family- Classical AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iOWBBibCvFk7"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vicPAcVsM08R"
   },
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IAp4kCWNNOuS"
   },
   "outputs": [],
   "source": [
    "X_train=X[:37911,:]\n",
    "X_test=X[37911:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1R6nytTCaXuU"
   },
   "outputs": [],
   "source": [
    "y_train=y[:37911,]\n",
    "y_test=y[37911:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j_shr0mcZsQh"
   },
   "outputs": [],
   "source": [
    "n_inputs=X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UCBTK8k0MqlC"
   },
   "outputs": [],
   "source": [
    "# Encoder\n",
    "visible = Input(shape=(n_inputs,))\n",
    "# encoder level 1\n",
    "e = Dense(n_inputs*2)(visible)\n",
    "e = BatchNormalization()(e)\n",
    "e = LeakyReLU()(e)\n",
    "# encoder level 2\n",
    "e = Dense(n_inputs)(e)\n",
    "e = BatchNormalization()(e)\n",
    "e = LeakyReLU()(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zP56oipAZ5FZ"
   },
   "outputs": [],
   "source": [
    "#Bottleneck\n",
    "n_bottleneck = round(float(n_inputs) / 2.0)+1\n",
    "bottleneck = Dense(n_bottleneck)(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DbKhuA3SZ8Uk"
   },
   "outputs": [],
   "source": [
    "# define decoder, level 1\n",
    "d = Dense(n_inputs)(bottleneck)\n",
    "d = BatchNormalization()(d)\n",
    "d = LeakyReLU()(d)\n",
    "# decoder level 2\n",
    "d = Dense(n_inputs*2)(d)\n",
    "d = BatchNormalization()(d)\n",
    "d = LeakyReLU()(d)\n",
    "# output layer\n",
    "output = Dense(n_inputs, activation='linear')(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ByGSb6WPaKsP"
   },
   "outputs": [],
   "source": [
    "model = Model(inputs=visible, outputs=output)\n",
    "# compile autoencoder model\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YTvOtXYslFqT"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l0zOKpeyaXlA"
   },
   "outputs": [],
   "source": [
    "# plot the autoencoder\n",
    "plot_model(model, 'autoencoder_compress.png', show_shapes=True)\n",
    "# fit the autoencoder model to reconstruct input\n",
    "history = model.fit(X_train, X_train, epochs=150, batch_size=128, verbose=2, validation_data=(X_test,X_test))\n",
    "# plot loss\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NO_nz79tdBWm"
   },
   "outputs": [],
   "source": [
    "encoder = Model(inputs=visible, outputs=bottleneck)\n",
    "plot_model(encoder, 'encoder_compress.png', show_shapes=True)\n",
    "# save the encoder to file\n",
    "encoder.save('encoder.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "80-FTlVMl3XN"
   },
   "outputs": [],
   "source": [
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2vYdaKDbYuAA"
   },
   "outputs": [],
   "source": [
    "#Create new features from Autoencoders:\n",
    "X_train_compressed=encoder.predict(X_train)\n",
    "X_test_compressed=encoder.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TghKl3V_Zujf"
   },
   "outputs": [],
   "source": [
    "X_train_compressed = X_train_compressed.reshape((X_train_compressed.shape[0],X_train_compressed.shape[1],1))\n",
    "X_test_compressed = X_test_compressed.reshape((X_test_compressed.shape[0],X_test_compressed.shape[1],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xWLqbJPh2TP_"
   },
   "outputs": [],
   "source": [
    "print(X_train_compressed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nI4mBWARKQco"
   },
   "outputs": [],
   "source": [
    "X_train_compressed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NqO67ASYZK0y"
   },
   "outputs": [],
   "source": [
    "input_shape = X_train_compressed.shape[1:]\n",
    "\n",
    "model = build_model(input_shape,head_size=256,num_heads=1,ff_dim=4,num_transformer_blocks=4,mlp_units=[128],mlp_dropout=0.4,dropout=0.25,)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
    "metrics=[\"accuracy\"],)\n",
    "model.summary()\n",
    "callbacks = [keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)]\n",
    "model.fit(X_train_compressed,y_train,validation_split=0.2,epochs=25,batch_size=256,callbacks=callbacks,verbose=0)\n",
    "ypred=model.predict(X_test_compressed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZnQ8UeZga8oi"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "out=[]\n",
    "for i in range((ypred.shape[0])):\n",
    "    if ypred[i,0]>ypred[i,1]:\n",
    "       out.append(0)\n",
    "    else:\n",
    "       out.append(1)\n",
    "confusion_matrix(y_test,out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_QUdGYLAIEY5"
   },
   "source": [
    "# Autoencoder-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zz6-Hx-kIIcf"
   },
   "outputs": [],
   "source": [
    "evaluate_model(X_train_compressed,y_train,X_test_compressed,y_test,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wbCc38gh-_VK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oRJ-YjlP1rWE"
   },
   "outputs": [],
   "source": [
    "CNN_LSTM(X_train_compressed,y_train,X_test_compressed,y_test,1,1,X_train_compressed.shape[1])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
